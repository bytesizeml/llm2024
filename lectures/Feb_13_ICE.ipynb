{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiQvNkURTiOW"
      },
      "source": [
        "## 1. Go through and execute all coding blocks in the In-class Notebook we went through today. Make sure the settings, the code and the device you run the notebook on checks out fine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Libraries\n",
        "!pip3 install openai\n",
        "!pip3 install python-dotenv\n",
        "\n",
        "\n",
        "# 2. Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "import os\n",
        "print(os.system('ls'))\n",
        "\n",
        "os.chdir(os.curdir + \"/drive/MyDrive/Colab_Notebooks_LLM_2023\")\n",
        "\n",
        "# 3. Open AI API Access Setup\n",
        "import openai\n",
        "import os\n",
        "\n",
        "open_ai_key_file = \"openai_api_key_llm_2023.txt\" # Your OPEN AI Key in this file\n",
        "with open(open_ai_key_file, \"r\") as f:\n",
        "  for line in f:\n",
        "    OPENAI_KEY = line\n",
        "    break\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n"
      ],
      "metadata": {
        "id": "swkqNinHwnPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_KEY)\n",
        "def get_completion_instruct(prompt, model=\"gpt-3.5-turbo-instruct\"):\n",
        "    response = client.completions.create(\n",
        "        model=model,\n",
        "        prompt=prompt\n",
        "    )\n",
        "    #return response.choices[0].text\n",
        "    return response.choices[0].text\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "  message = {\"role\": \"user\", \"content\": prompt}\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[message]\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "DqaJfYoKwyeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAToY3WQaAe1"
      },
      "source": [
        "## 2. Load once vs Load every time!\n",
        "Let's look at the impact of not optimizing code on the run-time!\n",
        "\n",
        "You can re-use the timing method we used in the walkthrough notebook for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt4ujX8eaIIp"
      },
      "outputs": [],
      "source": [
        "# 2.1 Load the Fine-Tuned Image2Text Model you saved to your drive from the In-class Walkthrough Notebook (Look to 1m)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# How much time does it take?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Get Image Caption for any 10 images of your choice (Load Model everytime)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# Load the model from 2.1 each time you compute the image caption\n",
        "# How much time does it take on an average per image?\n"
      ],
      "metadata": {
        "id": "Nqlf1dpSxt_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Get Image Caption for any 10 images of your choice (Load model once)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# Load the model from 2.1 ONLY ONCE and then use the loaded model to compute the image caption for each of the 10 images\n",
        "# How much time does it take on an average per image?"
      ],
      "metadata": {
        "id": "ri8zCMyRx7MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42uHz7V9aI78"
      },
      "source": [
        "## 3. Impact of device on inference time\n",
        "Does using GPU really have an impact on inference time? Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Repeat 2.3 - Once with CPU runtime and once with GPU runtime\n",
        "# Report average times for both runs.\n",
        "\n",
        "# Do you find a difference?"
      ],
      "metadata": {
        "id": "GKiDmy4gyXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 Visualizer the heat map of the matrix\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "3AFkCphu0Z0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNKCRClTVC73"
      },
      "source": [
        "## 4. Text2Image2Text2Image2....\n",
        "\n",
        " Use Image2Text library/API along with Text2Image API to display the sequence of image transformations that happen when we \"recursively\" move from text to image to text to image to..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTaT54iVVdeE"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE!\n",
        "## a) Start with a seed image b) Get caption for the image using the model you have loaded earlier in this notebook c) Convert the text to image using OpenAI's API\n",
        "## d) You now have a new image. Repeat steps b) and c) to get a new image again.\n",
        "\n",
        "## Display the transformed images starting with the seed image in a row below"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}