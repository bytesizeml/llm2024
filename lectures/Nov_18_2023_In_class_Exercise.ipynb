{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiQvNkURTiOW"
      },
      "source": [
        "## 0. Go through and execute all coding blocks in the In-class Notebook we went through. Make sure the settings, the code and the device you run the notebook on checks out fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvIN7nV-TqKR"
      },
      "source": [
        "## 1. How's the temperature?\n",
        "\n",
        "Let's play with temperature setting in Text Generation API of OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up OpenAI API\n",
        "\n",
        "!pip3 install openai\n",
        "!pip3 install python-dotenv\n",
        "import openai\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "\n",
        "import os\n",
        "print(os.system('ls'))\n",
        "\n",
        "os.chdir(os.curdir + \"/drive/MyDrive/Colab_Notebooks_LLM_2023\")\n",
        "\n",
        "open_ai_key_file = \"openai_api_key_llm_2023.txt\"\n",
        "with open(open_ai_key_file, \"r\") as f:\n",
        "  for line in f:\n",
        "    OPENAI_KEY = line\n",
        "    break\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n"
      ],
      "metadata": {
        "id": "swkqNinHwnPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key  = OPENAI_KEY\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=1, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "DqaJfYoKwyeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Write a prompt to get a Haiku from ChatGPT with temperature = 0\n",
        "\n",
        "######### Your Code HERE#######"
      ],
      "metadata": {
        "id": "g24glc0HwVU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Write a prompt to get a Haiku from ChatGPT with temperature = 1\n",
        "\n",
        "######### Your Code HERE#######"
      ],
      "metadata": {
        "id": "NuXX-wMjwfUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Write a prompt to get a Haiku from ChatGPT with temperature = 2\n",
        "\n",
        "######### Your Code HERE#######"
      ],
      "metadata": {
        "id": "DA1Ul5Zjwgvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m67lFXQTe6Y",
        "outputId": "f73026d7-42a2-4cb5-b5e5-742536c64174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Mounted at /content/drive/\n",
            "0\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAToY3WQaAe1"
      },
      "source": [
        "## 2. Load once vs Load every time!\n",
        "Let's look at the impact of not optimizing code on the run-time!\n",
        "\n",
        "You can re-use the timing method we used in the walkthrough notebook for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rt4ujX8eaIIp"
      },
      "outputs": [],
      "source": [
        "# 2.1 Load the Fine-Tuned Image2Text Model you saved to your drive from the In-class Walkthrough Notebook (Look to 1m)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# How much time does it take?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Get Image Caption for any 10 images of your choice (Load Model everytime)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# Load the model from 2.1 each time you compute the image caption\n",
        "# How much time does it take on an average per image?\n"
      ],
      "metadata": {
        "id": "Nqlf1dpSxt_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Get Image Caption for any 10 images of your choice (Load model once)\n",
        "\n",
        "### Your CODE HERE ######\n",
        "\n",
        "# Load the model from 2.1 ONLY ONCE and then use the loaded model to compute the image caption for each of the 10 images\n",
        "# How much time does it take on an average per image?"
      ],
      "metadata": {
        "id": "ri8zCMyRx7MM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42uHz7V9aI78"
      },
      "source": [
        "## 3. Impact of device on inference time\n",
        "Does using GPU really have an impact on inference time? Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Repeat 2.3 - Once with CPU runtime and once with GPU runtime\n",
        "# Report average times for both runs.\n",
        "\n",
        "# Do you find a difference?"
      ],
      "metadata": {
        "id": "GKiDmy4gyXWi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51IYhYBUa1g"
      },
      "source": [
        "## 4. Image Distance Graph\n",
        "Given 10 images, build an adjacency matrix that measures the distance between every pair of images and store it in a matrix. Also visualize the heat map\n",
        "corresponding to the matrix. Red colors should represent more distance and blue represents less distance.\n",
        "\n",
        "You can use the same 10 images you used in 2.2 if you wish.\n",
        "\n",
        "This exercise is tied in with one of the deliverables in your mini-project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3Im80-AlVCHv"
      },
      "outputs": [],
      "source": [
        "######### YOUR CODE HERE ############\n",
        "\n",
        "# 4.1 Generate Image Embeddings for the 10 images\n",
        "\n",
        "# embeddings = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Define an adjaceny matrix - This will be of size 10x10 - Fill in each of the 100 cells with\n",
        "# the distance between pairs of images\n",
        "\n",
        "import numpy as np\n",
        "adjacency_matrix = np.zeros((10,10)) # Initialization with a 10x10 zero-filled matrix\n",
        "\n",
        "\n",
        "def get_cosine_similarity(vector_x, vector_y):\n",
        "  pass\n",
        "\n",
        "# Computing adjacency matrix\n",
        "for row in range(10):\n",
        "  for col in range(10):\n",
        "    similarity = get_cosine_similarity(embeddings[row], embeddings[col])\n",
        "    adjacency_matrix[row][col] = 1/(similarity + 0.1) # Distance is inversely proprotional to similarity\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NfRQlXCazgKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 Visualizer the heat map of the matrix\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "3AFkCphu0Z0r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNKCRClTVC73"
      },
      "source": [
        "## 6. Text2Image2Text2Image2....\n",
        "\n",
        "This is connected to one of the deliverables in the mini-project. Use Image2Text library/API along with Text2Image API to display the sequence of image transformations that happen when we \"recursively\" move from text to image to text to image to..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NTaT54iVVdeE"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE!\n",
        "## a) Start with a seed image b) Get caption for the image using the model you have loaded earlier in this notebook c) Convert the text to image using OpenAI's API\n",
        "## d) You now have a new image. Repeat steps b) and c) to get a new image again.\n",
        "\n",
        "## Display the transformed images starting with the seed image in a row below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jyq6V_0Vet2"
      },
      "source": [
        "## 5."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}