
# LLMs: From Transformers to GPT| Winter 2024

***
 
## Professional Masters Program | University of Washington, Seattle 

***


#### Instructor - [Dr. Karthik Mohan](https://www.ece.uw.edu/people/karthik-mohan/)

***


| [Home](index.md)  | [Lectures](lectures.md)    | [References](references.md) | [Demos](demos.md) | [About me](karthik.md) |


***

### Pre-requisites
The course assumes that you have the basics of machine learning and are comfortable coding in Python. If this is not the case, please reach out to the TAs or the instructor asap.
Set up is also key for success in the course. Assignment 1 partly takes care of the setup (coding environment, APIs, etc).

### Flavor of the Course
The course will be a modern introduction to deep learning, transformers, GPT and beyond. We will have a mix of concepts, examples, applications in the industry, theory, algorithms, code and demos. Expect a lot of hands-on
coding assignments and mini-projects. Towards the later half of the course, we will start to touch on the latest trends in Generative AI. 

### Lecture Dates
1.  Tuesday, 4-6 pm **In-person**
2. Thursday, 4-6 pm **Online**

### Course Syllabus

***
 
1. Introduction and Motivation for LLMs
1. Deep Learning and its evolution
1. Transformer Architecture
1. Embeddings
1. Similarity Search with Transformers and Embeddings 
1. Discriminative vs Generative Transformers
1. **It's just the stream of consciousness!** Purely Generative Tranformers: GPT, GPT-2, GPT-3
1. **What made ChatGPT so popular?** Fine-tuning and RLHF: GPT-3.5 and GPT-4
1. LLMs vs APIs
1. **If only you had prompted me!** Prompt Engineering
1. Use of APIs 
1. **To open or not to open?** Closed vs Open-source LLMs
1. **Privacy, cost and other issues?** Open-source LLMs: LLama, MixTral, Phi-1.5 and Phi-2
1. Fine-tuning LLMs
1. **Can you make my fine-tuning easy for me?** Tricks to fine-tune LLMs
1. **I can only handle smaller models!!** Distillation and its use-cases
1. **What do I do if I don't have enough data :-/** LLMs for Data Augmentation
1. **How can you trust an LLM?** Evaluating LLMs
1. **Show me the cool stuff!**: Question-Answering, Sentiment Analysis and more
1. **Is my data safe?** Privacy and building in-house LLMs with privacy constraints
1. **LLMs -> LVMs:** Moving from Language to Images and Videos
1. **How the heck can you generate an image from just text?** Stable Diffusion 

### Course Assesments (300 points)

***


|  | Assignment Type | Points | Due Date | Pdf | Starter Code (if any)
| --- | --- | --- | --- | --- | --- |
| 1 | Assignment 0 |  70 | November 11 (midnight) | [Assignment 0](Assessments/Assignment_0.pdf)  | [Starter Code](search_starter_code.py)  | 
| 2 | In-class coding assignments | 100 | To be finished in class |  |  |
| 3 | Mini-Project | 100 | November 19 (8 am PST) |[Mini-Project](Assessments/Mini_Project_LLM_2023.pdf) |[Text2Image Starter](Lectures/Text_to_Image_Demo.ipynb) | 
|  | | | | |[Image Walkthrough](Lectures/Nov_18_2023_Class_Walkthrough.ipynb)|
| 4 | Mini-Project Presentation | 30 | November 19 (In-class) | | |


